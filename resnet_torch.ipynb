{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"resnet_torch.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm","authorship_tag":"ABX9TyO38EpoBDH1Lr5a/GKirmkq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"PkT6iCTFui4s","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision.transforms as transforms\n","import torchvision\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from torchvision import datasets, transforms\n","from torch.utils.data import Dataset,DataLoader\n","import torch.optim as optim\n","import copy\n","import sys, time\n","from torch.autograd import Variable\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4VHTiM4aMdin","colab_type":"text"},"source":["# Data split "]},{"cell_type":"code","metadata":{"id":"fNrxXJPQJu6X","colab_type":"code","outputId":"2550407d-236d-4a06-acf2-5812e279aa7c","executionInfo":{"status":"ok","timestamp":1583504096099,"user_tz":-540,"elapsed":16302,"user":{"displayName":"안영빈","photoUrl":"","userId":"11009136941831442800"}},"colab":{"base_uri":"https://localhost:8080/","height":118}},"source":["from keras.datasets import cifar10\n","(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n","\n","X_valid = X_train[40000:]\n","X_train = X_train[:40000]\n","y_valid = y_train[40000:]\n","y_train = y_train[:40000]"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 11s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"o8pTYbRASpL9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":503},"outputId":"9cc96353-f5c1-4417-ceb7-696e6fb71e79","executionInfo":{"status":"ok","timestamp":1583506858941,"user_tz":-540,"elapsed":1049,"user":{"displayName":"안영빈","photoUrl":"","userId":"11009136941831442800"}}},"source":["class compare_catdog_dataset():\n","    def __init__(self,li):\n","        self.li = li\n","        self.len_train = len(li[0])\n","        self.len_valid = len(li[1])\n","        self.len_test = len(li[2])\n","    def __call__(self):\n","        #draw plt\n","        label = ['train', 'valid','test']\n","        data = [self.len_train,self.len_valid,self.len_test]\n","        plt.rcParams[\"font.size\"] = 12\n","        plt.figure(figsize=(12,8))\n","\n","        x = np.arange(len(label))\n","\n","        plt.bar(x, [self.len_train,self.len_valid,self.len_test], label='data', width=0.3, color='#FFFF00')\n","        plt.legend()\n","        plt.xticks(x, label)\n","        plt.ylabel('Number of data')\n","        plt.title('Compare DATASETS')\n","        plt.show()\n","\n","show =compare_catdog_dataset([X_train,X_valid,X_test])\n","show()"],"execution_count":38,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAukAAAHmCAYAAADOehBDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n","text/plain":["<Figure size 864x576 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"aYpehu5WM4pk","colab_type":"text"},"source":["# Aug Comporse"]},{"cell_type":"code","metadata":{"id":"BrceYpiAlnzj","colab_type":"code","colab":{}},"source":["train_transform = transforms.Compose([transforms.ToPILImage(),\n","                                      transforms.RandomCrop(32, padding=3),\n","                                      transforms.RandomHorizontalFlip(),\n","                                      transforms.ToTensor(),\n","                                      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n","                                      ])\n","test_transform = transforms.Compose([transforms.ToTensor(),\n","                                     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n","                                     ])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DFWhq9JTNEqM","colab_type":"text"},"source":["#DataSet"]},{"cell_type":"code","metadata":{"id":"LCwOxQprm0O6","colab_type":"code","colab":{}},"source":["class cifar_Dataset(Dataset):\n","    def __init__(self,X,y, transform =None):\n","        self.transform = transform\n","        self.image_list = X\n","        self.label_list = y\n","\n","    def __len__(self):\n","        return len(self.label_list)\n","\n","    def __getitem__(self,idx):\n","        img = self.image_list[idx]\n","        label = self.label_list[idx][0]\n","        if self.transform:\n","            result = self.transform(img)\n","        return result, label"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hX9FPZ2uontI","colab_type":"code","colab":{}},"source":["Trainset = cifar_Dataset(X = X_train,y = y_train, transform=train_transform)\n","Valset = cifar_Dataset(X = X_valid,y = y_valid, transform= test_transform)\n","Testset = cifar_Dataset(X = X_test, y = y_test, transform = test_transform)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EjJ7ULFmsIWA","colab_type":"code","colab":{}},"source":["trainloader = torch.utils.data.DataLoader(Trainset, batch_size=32, shuffle=True, num_workers=1)\n","Valloader = torch.utils.data.DataLoader(Valset, batch_size=32, shuffle=True, num_workers=1)\n","testloader = torch.utils.data.DataLoader(Testset, batch_size=32, shuffle=False, num_workers=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B61U20vTspsR","colab_type":"code","colab":{}},"source":["classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hg16JUVfNUP0","colab_type":"text"},"source":["# Model 생성"]},{"cell_type":"code","metadata":{"id":"EYYsFXbOu4Op","colab_type":"code","colab":{}},"source":["class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(Bottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = F.relu(self.bn2(self.conv2(out)))\n","        out = self.bn3(self.conv3(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 64\n","\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n","        self.linear = nn.Linear(512*block.expansion, num_classes)\n","\n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = F.avg_pool2d(out, 4)\n","        out = out.view(out.size(0), -1)\n","        out = self.linear(out)\n","        return out\n","\n","\n","def ResNet18():\n","    return ResNet(BasicBlock, [2,2,2,2])\n","\n","def ResNet34():\n","    return ResNet(BasicBlock, [3,4,6,3])\n","\n","def ResNet50():\n","    return ResNet(Bottleneck, [3,4,6,3])\n","\n","def ResNet101():\n","    return ResNet(Bottleneck, [3,4,23,3])\n","\n","def ResNet152():\n","    return ResNet(Bottleneck, [3,8,36,3])\n","\n","\n","def test():\n","    net = ResNet50()\n","    y = net(torch.randn(1,3,32,32))\n","    print(y.size())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"R-oJ75NF0JjU","colab_type":"code","outputId":"e4125b65-cae7-49eb-ed4b-afe706d0a96e","executionInfo":{"status":"ok","timestamp":1583504384583,"user_tz":-540,"elapsed":1417,"user":{"displayName":"안영빈","photoUrl":"","userId":"11009136941831442800"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model = ResNet50()\n","from torchsummary import summary\n","summary(model.cuda(), (3,32,32))\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 32, 32]           1,728\n","       BatchNorm2d-2           [-1, 64, 32, 32]             128\n","            Conv2d-3           [-1, 64, 32, 32]           4,096\n","       BatchNorm2d-4           [-1, 64, 32, 32]             128\n","            Conv2d-5           [-1, 64, 32, 32]          36,864\n","       BatchNorm2d-6           [-1, 64, 32, 32]             128\n","            Conv2d-7          [-1, 256, 32, 32]          16,384\n","       BatchNorm2d-8          [-1, 256, 32, 32]             512\n","            Conv2d-9          [-1, 256, 32, 32]          16,384\n","      BatchNorm2d-10          [-1, 256, 32, 32]             512\n","       Bottleneck-11          [-1, 256, 32, 32]               0\n","           Conv2d-12           [-1, 64, 32, 32]          16,384\n","      BatchNorm2d-13           [-1, 64, 32, 32]             128\n","           Conv2d-14           [-1, 64, 32, 32]          36,864\n","      BatchNorm2d-15           [-1, 64, 32, 32]             128\n","           Conv2d-16          [-1, 256, 32, 32]          16,384\n","      BatchNorm2d-17          [-1, 256, 32, 32]             512\n","       Bottleneck-18          [-1, 256, 32, 32]               0\n","           Conv2d-19           [-1, 64, 32, 32]          16,384\n","      BatchNorm2d-20           [-1, 64, 32, 32]             128\n","           Conv2d-21           [-1, 64, 32, 32]          36,864\n","      BatchNorm2d-22           [-1, 64, 32, 32]             128\n","           Conv2d-23          [-1, 256, 32, 32]          16,384\n","      BatchNorm2d-24          [-1, 256, 32, 32]             512\n","       Bottleneck-25          [-1, 256, 32, 32]               0\n","           Conv2d-26          [-1, 128, 32, 32]          32,768\n","      BatchNorm2d-27          [-1, 128, 32, 32]             256\n","           Conv2d-28          [-1, 128, 16, 16]         147,456\n","      BatchNorm2d-29          [-1, 128, 16, 16]             256\n","           Conv2d-30          [-1, 512, 16, 16]          65,536\n","      BatchNorm2d-31          [-1, 512, 16, 16]           1,024\n","           Conv2d-32          [-1, 512, 16, 16]         131,072\n","      BatchNorm2d-33          [-1, 512, 16, 16]           1,024\n","       Bottleneck-34          [-1, 512, 16, 16]               0\n","           Conv2d-35          [-1, 128, 16, 16]          65,536\n","      BatchNorm2d-36          [-1, 128, 16, 16]             256\n","           Conv2d-37          [-1, 128, 16, 16]         147,456\n","      BatchNorm2d-38          [-1, 128, 16, 16]             256\n","           Conv2d-39          [-1, 512, 16, 16]          65,536\n","      BatchNorm2d-40          [-1, 512, 16, 16]           1,024\n","       Bottleneck-41          [-1, 512, 16, 16]               0\n","           Conv2d-42          [-1, 128, 16, 16]          65,536\n","      BatchNorm2d-43          [-1, 128, 16, 16]             256\n","           Conv2d-44          [-1, 128, 16, 16]         147,456\n","      BatchNorm2d-45          [-1, 128, 16, 16]             256\n","           Conv2d-46          [-1, 512, 16, 16]          65,536\n","      BatchNorm2d-47          [-1, 512, 16, 16]           1,024\n","       Bottleneck-48          [-1, 512, 16, 16]               0\n","           Conv2d-49          [-1, 128, 16, 16]          65,536\n","      BatchNorm2d-50          [-1, 128, 16, 16]             256\n","           Conv2d-51          [-1, 128, 16, 16]         147,456\n","      BatchNorm2d-52          [-1, 128, 16, 16]             256\n","           Conv2d-53          [-1, 512, 16, 16]          65,536\n","      BatchNorm2d-54          [-1, 512, 16, 16]           1,024\n","       Bottleneck-55          [-1, 512, 16, 16]               0\n","           Conv2d-56          [-1, 256, 16, 16]         131,072\n","      BatchNorm2d-57          [-1, 256, 16, 16]             512\n","           Conv2d-58            [-1, 256, 8, 8]         589,824\n","      BatchNorm2d-59            [-1, 256, 8, 8]             512\n","           Conv2d-60           [-1, 1024, 8, 8]         262,144\n","      BatchNorm2d-61           [-1, 1024, 8, 8]           2,048\n","           Conv2d-62           [-1, 1024, 8, 8]         524,288\n","      BatchNorm2d-63           [-1, 1024, 8, 8]           2,048\n","       Bottleneck-64           [-1, 1024, 8, 8]               0\n","           Conv2d-65            [-1, 256, 8, 8]         262,144\n","      BatchNorm2d-66            [-1, 256, 8, 8]             512\n","           Conv2d-67            [-1, 256, 8, 8]         589,824\n","      BatchNorm2d-68            [-1, 256, 8, 8]             512\n","           Conv2d-69           [-1, 1024, 8, 8]         262,144\n","      BatchNorm2d-70           [-1, 1024, 8, 8]           2,048\n","       Bottleneck-71           [-1, 1024, 8, 8]               0\n","           Conv2d-72            [-1, 256, 8, 8]         262,144\n","      BatchNorm2d-73            [-1, 256, 8, 8]             512\n","           Conv2d-74            [-1, 256, 8, 8]         589,824\n","      BatchNorm2d-75            [-1, 256, 8, 8]             512\n","           Conv2d-76           [-1, 1024, 8, 8]         262,144\n","      BatchNorm2d-77           [-1, 1024, 8, 8]           2,048\n","       Bottleneck-78           [-1, 1024, 8, 8]               0\n","           Conv2d-79            [-1, 256, 8, 8]         262,144\n","      BatchNorm2d-80            [-1, 256, 8, 8]             512\n","           Conv2d-81            [-1, 256, 8, 8]         589,824\n","      BatchNorm2d-82            [-1, 256, 8, 8]             512\n","           Conv2d-83           [-1, 1024, 8, 8]         262,144\n","      BatchNorm2d-84           [-1, 1024, 8, 8]           2,048\n","       Bottleneck-85           [-1, 1024, 8, 8]               0\n","           Conv2d-86            [-1, 256, 8, 8]         262,144\n","      BatchNorm2d-87            [-1, 256, 8, 8]             512\n","           Conv2d-88            [-1, 256, 8, 8]         589,824\n","      BatchNorm2d-89            [-1, 256, 8, 8]             512\n","           Conv2d-90           [-1, 1024, 8, 8]         262,144\n","      BatchNorm2d-91           [-1, 1024, 8, 8]           2,048\n","       Bottleneck-92           [-1, 1024, 8, 8]               0\n","           Conv2d-93            [-1, 256, 8, 8]         262,144\n","      BatchNorm2d-94            [-1, 256, 8, 8]             512\n","           Conv2d-95            [-1, 256, 8, 8]         589,824\n","      BatchNorm2d-96            [-1, 256, 8, 8]             512\n","           Conv2d-97           [-1, 1024, 8, 8]         262,144\n","      BatchNorm2d-98           [-1, 1024, 8, 8]           2,048\n","       Bottleneck-99           [-1, 1024, 8, 8]               0\n","          Conv2d-100            [-1, 512, 8, 8]         524,288\n","     BatchNorm2d-101            [-1, 512, 8, 8]           1,024\n","          Conv2d-102            [-1, 512, 4, 4]       2,359,296\n","     BatchNorm2d-103            [-1, 512, 4, 4]           1,024\n","          Conv2d-104           [-1, 2048, 4, 4]       1,048,576\n","     BatchNorm2d-105           [-1, 2048, 4, 4]           4,096\n","          Conv2d-106           [-1, 2048, 4, 4]       2,097,152\n","     BatchNorm2d-107           [-1, 2048, 4, 4]           4,096\n","      Bottleneck-108           [-1, 2048, 4, 4]               0\n","          Conv2d-109            [-1, 512, 4, 4]       1,048,576\n","     BatchNorm2d-110            [-1, 512, 4, 4]           1,024\n","          Conv2d-111            [-1, 512, 4, 4]       2,359,296\n","     BatchNorm2d-112            [-1, 512, 4, 4]           1,024\n","          Conv2d-113           [-1, 2048, 4, 4]       1,048,576\n","     BatchNorm2d-114           [-1, 2048, 4, 4]           4,096\n","      Bottleneck-115           [-1, 2048, 4, 4]               0\n","          Conv2d-116            [-1, 512, 4, 4]       1,048,576\n","     BatchNorm2d-117            [-1, 512, 4, 4]           1,024\n","          Conv2d-118            [-1, 512, 4, 4]       2,359,296\n","     BatchNorm2d-119            [-1, 512, 4, 4]           1,024\n","          Conv2d-120           [-1, 2048, 4, 4]       1,048,576\n","     BatchNorm2d-121           [-1, 2048, 4, 4]           4,096\n","      Bottleneck-122           [-1, 2048, 4, 4]               0\n","          Linear-123                   [-1, 10]          20,490\n","================================================================\n","Total params: 23,520,842\n","Trainable params: 23,520,842\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 66.13\n","Params size (MB): 89.72\n","Estimated Total Size (MB): 155.86\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"H2qWF0QObHUW","colab_type":"text"},"source":["#Train & Test"]},{"cell_type":"code","metadata":{"id":"IDI42WFUvVmC","colab_type":"code","colab":{}},"source":["class TrainModel():\n","    def __init__(self,model, criterion, optimizer, trainloader, testloader, num_epochs=5):\n","        \n","        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","        self.model = model.to(self.device)\n","        self.trainloader =trainloader\n","        self.testloader = testloader\n","        self.criterion = criterion\n","        self.optimizer = optimizer\n","        self.num_epochs = num_epochs\n","        self.best_acc_wts = copy.deepcopy(self.model.state_dict())\n","        self.best_acc =0.0\n","\n","        \n","        for epoch in range(1, self.num_epochs+1):\n","            print('Epoch {}/{}'.format(epoch, self.num_epochs))\n","            self.train()\n","            self.test()\n","\n","        model.load_state_dict(self.best_acc_wts)\n","\n","    def train(self):\n","        self.model.train()\n","        train_loss = 0\n","        correct = 0\n","        total = 0\n","        for batch_idx, (inputs, targets) in enumerate(self.trainloader):\n","            inputs, targets = inputs.to(self.device), targets.to(self.device)\n","            self.optimizer.zero_grad()\n","            outputs = self.model(inputs)\n","            loss = self.criterion(outputs, targets.long())\n","            loss.backward()\n","            self.optimizer.step()\n","\n","            train_loss += loss.data.cpu().numpy()\n","            _, predicted = outputs.max(1)\n","            total += targets.size(0)\n","            correct += predicted.eq(targets).sum().item()\n","\n","        epoch_loss = train_loss /len(self.trainloader)\n","        epoch_acc = correct / total\n","        print('train | Loss: {:.4f} Acc: {:.4f}'.format( epoch_loss, epoch_acc))\n","\n","    def test(self):\n","        global best_acc\n","        self.model.eval()\n","        test_loss = 0\n","        correct = 0\n","        total = 0\n","        with torch.no_grad():\n","            for batch_idx, (inputs, targets) in enumerate(self.testloader):\n","                inputs, targets = inputs.to(self.device), targets.to(self.device)\n","                outputs = self.model(inputs)\n","                loss = self.criterion(outputs, targets.long())\n","\n","                test_loss += loss.data.cpu().numpy()\n","                _, predicted = outputs.max(1)\n","                total += targets.size(0)\n","                correct += predicted.eq(targets).sum().item()\n","\n","            epoch_loss = test_loss /len(self.testloader)\n","            epoch_acc = correct / total\n","            print('test | Loss: {:.4f} Acc: {:.4f}'.format( epoch_loss, epoch_acc))\n","            if epoch_acc >= self.best_acc:\n","                self.best_acc = epoch_acc\n","                self.best_acc_wts = copy.deepcopy(self.model.state_dict())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gI2P2_b57Xna","colab_type":"code","colab":{}},"source":["TrainModel(model, criterion=criterion, optimizer=optimizer,trainloader=trainloader,testloader=valloader,num_epochs=30)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SCHkuD0237k-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"c0ff48c5-a836-4c7f-afaa-39ffe3b17f19","executionInfo":{"status":"ok","timestamp":1583510686554,"user_tz":-540,"elapsed":9725,"user":{"displayName":"안영빈","photoUrl":"","userId":"11009136941831442800"}}},"source":[" def test(model,testloader,criterion):\n","        model.eval()\n","        test_loss = 0\n","        correct = 0\n","        total = 0\n","        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","        with torch.no_grad():\n","            for batch_idx, (inputs, targets) in enumerate(testloader):\n","                inputs,targets = inputs.to(device), targets.to(device)\n","                outputs = model(inputs)\n","                loss = criterion(outputs, targets.long())     \n","\n","                test_loss += loss.data.cpu().numpy()\n","                _, predicted = outputs.max(1)\n","                total += targets.size(0)\n","                correct += predicted.eq(targets).sum().item()\n","                \n","            epoch_loss = test_loss / len(testloader)\n","            epoch_acc = correct / total\n","            print('test | Loss: {:.4f} Acc: {:.4f}'.format( epoch_loss, epoch_acc))\n","\n","test(model,testloader,criterion)"],"execution_count":60,"outputs":[{"output_type":"stream","text":["test | Loss: 0.3551 Acc: 0.8900\n"],"name":"stdout"}]}]}